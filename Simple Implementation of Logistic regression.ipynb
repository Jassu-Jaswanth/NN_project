{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb14baa",
   "metadata": {},
   "source": [
    "Lets import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91941ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as spy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08939b3a",
   "metadata": {},
   "source": [
    "We need datasets to do this.\n",
    "A simple data set is a set of images with 64x64 pixel with three color code (RBG)\n",
    "\n",
    "first we need a library to import images. One such library is pillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3209e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eecf82",
   "metadata": {},
   "source": [
    "Refer to the doucumentation of Image.\n",
    "https://pillow.readthedocs.io/en/stable/reference/Image.html\n",
    "\n",
    "Now that we have our dataset of images and we need to compress it to the required 64x64 size\n",
    "using our Image module that we have imported.\n",
    "\n",
    "There is function called \"thumbnail\" which gives a lower resoulution picture.\n",
    "Also that we need RBG values of these thumbnails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70129a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2eda0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "size = (64,64)\n",
    "dataset = []\n",
    "train_set_y = []\n",
    "for infile in glob.glob(\"./imageset/*.jpg\"):\n",
    "    padded_img = np.full((64,64,3),1)\n",
    "    file,ext = os.path.splitext(infile)\n",
    "    if \"paper\" in file:\n",
    "        train_set_y += [1.0]\n",
    "    else:\n",
    "        train_set_y += [0.0]\n",
    "    with Image.open(infile) as im:\n",
    "        im.thumbnail(size)\n",
    "        rgb = im.convert('RGB')\n",
    "        rgb_vals = np.array(rgb)\n",
    "        shape = rgb_vals.shape\n",
    "        padded_img[:shape[0],:shape[1],:] = rgb_vals\n",
    "        # One can convert and save this padded array into images if one wants.\n",
    "        # Also one can convert this whole into a funtion with a parameter(string:a path to images).\n",
    "        dataset += [padded_img]\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "train_set_y = np.array(train_set_y).reshape(1,len(train_set_y))\n",
    "print(train_set_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898e533",
   "metadata": {},
   "source": [
    "Lets Try to detect images with papers in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12ae26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by forming all r's , g's and b's in a single row vector\n",
    "\n",
    "X = np.full((dataset.shape[0],64*64*3),0)\n",
    "i = 0\n",
    "for dat_img in dataset:\n",
    "    X[i][:] = dat_img.reshape(1,64*64*3)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aafdbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1016)\n"
     ]
    }
   ],
   "source": [
    "# Define\n",
    "#     w is (1,64*64*3) shaped array\n",
    "#     b is a real number\n",
    "#\n",
    "#     z = w.T times X plus b\n",
    "\n",
    "# Initializing w and b\n",
    "w = np.full((1,64*64*3),2.0)\n",
    "b = 2.0\n",
    "\n",
    "# Also don't forget to standaradize the rgb vector dataset\n",
    "\n",
    "def evaluate(w,b,X):\n",
    "    shape = X.shape\n",
    "    # Although we need to divide by standard deviation, 128 works fine\n",
    "    standard = X\n",
    "    z = np.dot(w,np.transpose(standard)) + b\n",
    "    sigmond = 1/(1 + np.exp(-z))\n",
    "    return sigmond\n",
    "\n",
    "y_hat = evaluate(w,b,X)\n",
    "print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35016a",
   "metadata": {},
   "source": [
    "Now let's write the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8379d8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasawanth\\AppData\\Local\\Temp\\ipykernel_15420\\3452308363.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  cost_val = (-1/y.shape[1])*( np.dot(np.log(y_hat),y.transpose()) + np.dot(np.log(1 - y_hat),1 - y.transpose()) )\n"
     ]
    }
   ],
   "source": [
    "def cost(y_hat,y):\n",
    "    assert(y.shape[1] > 0)\n",
    "    cost_val = (-1/y.shape[1])*( np.dot(np.log(y_hat),y.transpose()) + np.dot(np.log(1 - y_hat),1 - y.transpose()) )\n",
    "    return cost_val\n",
    "\n",
    "cost_val = cost(y_hat,train_set_y)\n",
    "print(cost_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "729168c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jasawanth\\AppData\\Local\\Temp\\ipykernel_15420\\3452308363.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  cost_val = (-1/y.shape[1])*( np.dot(np.log(y_hat),y.transpose()) + np.dot(np.log(1 - y_hat),1 - y.transpose()) )\n",
      "C:\\Users\\Jasawanth\\AppData\\Local\\Temp\\ipykernel_15420\\1356929710.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  sigmond = 1/(1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[-119903. -117201. -112754. ...    -921.    -921.    -921.]]\n",
      "1.0915354330708662\n"
     ]
    }
   ],
   "source": [
    "# We will now try to reduce the above cost by iterating many times and getting the perfect parameters with lowest cost\n",
    "#\n",
    "# By the way, variable \"alpha\" is going to be the learning rate\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "\n",
    "def propagate(w,b,X,y,learn_cycles,learn_rate):\n",
    "    w_trained = w\n",
    "    b_trained = b\n",
    "    for i in range(learn_cycles):\n",
    "        y_hat = evaluate(w_trained,b_trained,X)\n",
    "        cost_val = cost(y_hat,y)\n",
    "        db = (y_hat - y)\n",
    "        dw = np.dot(db,X)\n",
    "        w_trained = w_trained - dw * learn_rate\n",
    "        b_trained = b_trained - (int(db.sum())/X.shape[0]) * learn_rate\n",
    "        assert(dw.shape == w.shape)\n",
    "        print(cost_val)\n",
    "    return w_trained, b_trained\n",
    "\n",
    "w_trained, b_trained = propagate(w,b,X,train_set_y,5,1)\n",
    "print(w_trained)\n",
    "print(b_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dea495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
